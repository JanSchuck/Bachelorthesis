{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60e93a9",
   "metadata": {},
   "source": [
    "# Analysing german news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3580a6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95e7dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba431337",
   "metadata": {},
   "source": [
    "## Load data into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "28871d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16645 entries, 0 to 41555\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Titel                  16645 non-null  object \n",
      " 1   Date_Info              16645 non-null  object \n",
      " 2   URL                    16645 non-null  object \n",
      " 3   Overline               10049 non-null  object \n",
      " 4   Breadcrumb             7682 non-null   object \n",
      " 5   author                 1672 non-null   object \n",
      " 6   detailed_informations  2366 non-null   object \n",
      " 7   Zugriff_Datum          10345 non-null  float64\n",
      " 8   News_page              16645 non-null  object \n",
      " 9   Unnamed: 0             0 non-null      object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Folderpath to CSV's\n",
    "CSV_folderPath=\"/Users/jan/Documents/Python_Projects/Bachelorthesis/CSV_Backlog\"\n",
    "\n",
    "# Initialize list<csv> for Spiegel, Sueddeutsche, Bild and combined \n",
    "Spiegel_csvs = []\n",
    "Sueddeutsche_csvs = []\n",
    "Bild_csvs = []\n",
    "Combi_csvs = []\n",
    "\n",
    "\n",
    "# Change directory to CSV_folderPath\n",
    "os.chdir(CSV_folderPath)\n",
    "\n",
    "# iterate over all files\n",
    "for file in os.listdir():\n",
    "    # read csv to dataframe\n",
    "    df =pd.read_csv(file, index_col=None, header=0)\n",
    "    # all df append to combi...\n",
    "    Combi_csvs.append(df)\n",
    "    # sort dataframe to its list\n",
    "    #Spiegel\n",
    "    if file.startswith(\"Spiegel\"):\n",
    "        Spiegel_csvs.append(df)\n",
    "    # Sueddeutsche\n",
    "    elif file.startswith(\"Sueddeutsche\"):\n",
    "        Sueddeutsche_csvs.append(df)\n",
    "    # Bild\n",
    "    elif file.startswith(\"Bild\"):\n",
    "        Bild_csvs.append(df)\n",
    "    \n",
    "All_articles = pd.concat(Combi_csvs, axis=0, ignore_index=True)\n",
    "Spiegel_articles = pd.concat(Spiegel_csvs, axis=0, ignore_index=True)\n",
    "Sueddeutsche_articles = pd.concat(Sueddeutsche_csvs, axis=0, ignore_index=True)\n",
    "if(len(Bild_csvs)) != 0:\n",
    "    Bild_articles = pd.concat(Bild_csvs, axis=0, ignore_index=True)\n",
    "else:\n",
    "    Bild_articles=[]\n",
    "\n",
    "    \n",
    "# Drop duplicates\n",
    "\n",
    "# All articles\n",
    "All_articles= All_articles.drop_duplicates(subset=\"Titel\")\n",
    "\n",
    "# Spiegel articles\n",
    "Spiegel_articles = Spiegel_articles.drop_duplicates(subset=\"Titel\")\n",
    "\n",
    "# Sueddeutsch articles\n",
    "Sueddeutsche_articles = Sueddeutsche_articles.drop_duplicates(subset=\"Titel\")\n",
    "\n",
    "# Bild articles\n",
    "#Bild_articles = Bild_articles.drop_duplicates(subset=\"title\")\n",
    "All_articles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef259a",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42ee5f",
   "metadata": {},
   "source": [
    "### Cast Date_Info to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "53322530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# All articles\n",
    "All_articles[\"Date_Info\"] = All_articles[\"Date_Info\"].str.strip()\n",
    "All_articles[\"Date_Info\"] = pd.to_datetime(All_articles[\"Date_Info\"], format='%d%m%Y_%H:%M')\n",
    "# Spiegel articles\n",
    "Spiegel_articles[\"Date_Info\"] = Spiegel_articles[\"Date_Info\"].str.strip()\n",
    "Spiegel_articles[\"Date_Info\"] = pd.to_datetime(Spiegel_articles[\"Date_Info\"], format='%d%m%Y_%H:%M')\n",
    "# Sueddeutsche articles\n",
    "Sueddeutsche_articles[\"Date_Info\"] = Sueddeutsche_articles[\"Date_Info\"].str.strip()\n",
    "Sueddeutsche_articles[\"Date_Info\"] = pd.to_datetime(Sueddeutsche_articles[\"Date_Info\"], format='%d%m%Y_%H:%M')\n",
    "# Bild articles\n",
    "#Bild_carticles[\"Date_Info\"] = pd.to_datetime(Bild_carticles[\"Date_Info\"], format='%d%m%Y_%H:%M')\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038bca1",
   "metadata": {},
   "source": [
    "## Initial data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc012469",
   "metadata": {},
   "source": [
    "### Ammount of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1e69392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiegel articles: 6300\n",
      "Sueddeutsche articles: 10346\n",
      "Bild articles: 0\n",
      "Overall: 16645\n"
     ]
    }
   ],
   "source": [
    "# Spiegel articles\n",
    "ammount_of_Spiegel_articles = len(Spiegel_articles)\n",
    "print(f\"Spiegel articles: {ammount_of_Spiegel_articles}\")\n",
    "\n",
    "# Sueddeutsche articles\n",
    "ammount_of_Sueddeutsche_articles = len(Sueddeutsche_articles)\n",
    "print(f\"Sueddeutsche articles: {ammount_of_Sueddeutsche_articles}\")\n",
    "\n",
    "# Bild articles\n",
    "ammount_of_Bild_articles = len(Bild_articles)\n",
    "print(f\"Bild articles: {ammount_of_Bild_articles}\")\n",
    "\n",
    "# All articles\n",
    "ammount_of_Combined_articles = len(All_articles)\n",
    "print(f\"Overall: {ammount_of_Combined_articles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ccf86",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4a4fc",
   "metadata": {},
   "source": [
    "### Exploding titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f7f5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_titles(title_column):\n",
    "    title_column =title_column.to_frame()\n",
    "    tokenized_titles=[]\n",
    "    title_column[\"tokenized_title\"] = \"\"\n",
    "    for index, row in title_column.iterrows():\n",
    "        # tokenize\n",
    "        tokenized_title = word_tokenize(row.Titel)\n",
    "        \n",
    "        # remove stopwords & numbers/punction\n",
    "        tokenized_title = [word for word in tokenized_title if word not in stopwords.words(\"german\")]\n",
    "        \n",
    "        # add to row\n",
    "        row.tokenized_title = tokenized_title\n",
    "        \n",
    "    return title_column\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50943502",
   "metadata": {},
   "source": [
    "### Tokenize All_articles Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0d9cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_articles[\"tokenized_titles\"] = explode_titles(All_articles[\"Titel\"]).tokenized_title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
