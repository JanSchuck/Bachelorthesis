{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ea68f1",
   "metadata": {},
   "source": [
    "# Analysing german news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0155c4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7377d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is an open source data analysis and manipulation tool\n",
    "import pandas as pd\n",
    "# os gives access to the operating system\n",
    "import os\n",
    "# The datetime module supplies classes for manipulating dates and times.\n",
    "from datetime import datetime \n",
    "import datetime\n",
    "# This module provides various time-related functions.\n",
    "import time\n",
    "\n",
    "# Natural language toolkit\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# library to create visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "\n",
    "# open source library for automating downloading of reports from Google Trends\n",
    "from pytrends.request import TrendReq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8abf3d7",
   "metadata": {},
   "source": [
    "## Load data into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c9919b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29436 entries, 0 to 70452\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Titel                  29436 non-null  object \n",
      " 1   Date_Info              29436 non-null  object \n",
      " 2   URL                    29436 non-null  object \n",
      " 3   Overline               20256 non-null  object \n",
      " 4   Breadcrumb             14851 non-null  object \n",
      " 5   author                 3643 non-null   object \n",
      " 6   detailed_informations  5148 non-null   object \n",
      " 7   Zugriff_Datum          20872 non-null  float64\n",
      " 8   News_page              29436 non-null  object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Folderpath to CSV's\n",
    "CSV_folderPath=\"/Users/jan/Documents/Python_Projects/Bachelorthesis/CSV_Backlog\"\n",
    "\n",
    "# Initialize list<csv> for Spiegel, Sueddeutsche, Bild and combined \n",
    "Spiegel_csvs = []\n",
    "Sueddeutsche_csvs = []\n",
    "Bild_csvs = []\n",
    "Combi_csvs = []\n",
    "\n",
    "\n",
    "# Change directory to CSV_folderPath\n",
    "os.chdir(CSV_folderPath)\n",
    "\n",
    "# iterate over all files\n",
    "for file in os.listdir():\n",
    "    # that are csvs...\n",
    "    if file.endswith(\".csv\"):        \n",
    "        # read csv to dataframe\n",
    "        df =pd.read_csv(file, index_col=None, header=0)\n",
    "        # all df append to combi...\n",
    "        Combi_csvs.append(df)\n",
    "        # sort dataframe to its list\n",
    "        #Spiegel\n",
    "        if file.startswith(\"Spiegel\"):\n",
    "            Spiegel_csvs.append(df)\n",
    "        # Sueddeutsche\n",
    "        elif file.startswith(\"Sueddeutsche\"):\n",
    "            Sueddeutsche_csvs.append(df)\n",
    "        # Bild\n",
    "        elif file.startswith(\"Bild\"):\n",
    "            Bild_csvs.append(df)\n",
    "    \n",
    "All_articles = pd.concat(Combi_csvs, axis=0, ignore_index=True)\n",
    "Spiegel_articles = pd.concat(Spiegel_csvs, axis=0, ignore_index=True)\n",
    "Sueddeutsche_articles = pd.concat(Sueddeutsche_csvs, axis=0, ignore_index=True)\n",
    "if(len(Bild_csvs)) != 0:\n",
    "    Bild_articles = pd.concat(Bild_csvs, axis=0, ignore_index=True)\n",
    "else:\n",
    "    Bild_articles=[]\n",
    "\n",
    "    \n",
    "# Drop duplicates\n",
    "\n",
    "# All articles\n",
    "All_articles= All_articles.drop_duplicates(subset=\"Titel\")\n",
    "\n",
    "# Spiegel articles\n",
    "Spiegel_articles = Spiegel_articles.drop_duplicates(subset=\"Titel\")\n",
    "\n",
    "# Sueddeutsch articles\n",
    "Sueddeutsche_articles = Sueddeutsche_articles.drop_duplicates(subset=\"Titel\")\n",
    "\n",
    "# Bild articles\n",
    "#Bild_articles = Bild_articles.drop_duplicates(subset=\"title\")\n",
    "All_articles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051ceb3",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96245ac",
   "metadata": {},
   "source": [
    "### Cast Date_Info to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dbf25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All articles\n",
    "All_articles[\"Date_Info\"] = All_articles[\"Date_Info\"].str.strip()\n",
    "All_articles[\"Date_Info\"] = pd.to_datetime(All_articles[\"Date_Info\"], format='%d%m%Y_%H:%M')\n",
    "# Spiegel articles\n",
    "Spiegel_articles[\"Date_Info\"] = Spiegel_articles[\"Date_Info\"].str.strip()\n",
    "Spiegel_articles[\"Date_Info\"] = pd.to_datetime(Spiegel_articles[\"Date_Info\"], format='%d%m%Y_%H:%M')\n",
    "# Sueddeutsche articles\n",
    "Sueddeutsche_articles[\"Date_Info\"] = Sueddeutsche_articles[\"Date_Info\"].str.strip()\n",
    "Sueddeutsche_articles[\"Date_Info\"] = pd.to_datetime(Sueddeutsche_articles[\"Date_Info\"], format='%d%m%Y_%H:%M')\n",
    "# Bild articles\n",
    "#Bild_carticles[\"Date_Info\"] = pd.to_datetime(Bild_carticles[\"Date_Info\"], format='%d%m%Y_%H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95f57d",
   "metadata": {},
   "source": [
    "## Initial data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c10238",
   "metadata": {},
   "source": [
    "### Ammount of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a18b9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiegel articles: 8564\n",
      "Sueddeutsche articles: 20873\n",
      "Bild articles: 0\n",
      "Overall: 29436\n"
     ]
    }
   ],
   "source": [
    "# Spiegel articles\n",
    "ammount_of_Spiegel_articles = len(Spiegel_articles)\n",
    "print(f\"Spiegel articles: {ammount_of_Spiegel_articles}\")\n",
    "\n",
    "# Sueddeutsche articles\n",
    "ammount_of_Sueddeutsche_articles = len(Sueddeutsche_articles)\n",
    "print(f\"Sueddeutsche articles: {ammount_of_Sueddeutsche_articles}\")\n",
    "\n",
    "# Bild articles\n",
    "ammount_of_Bild_articles = len(Bild_articles)\n",
    "print(f\"Bild articles: {ammount_of_Bild_articles}\")\n",
    "\n",
    "# All articles\n",
    "ammount_of_Combined_articles = len(All_articles)\n",
    "print(f\"Overall: {ammount_of_Combined_articles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028cc12",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b08af",
   "metadata": {},
   "source": [
    "### Exploding titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd3f630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_titles(title_column):\n",
    "    title_column =title_column.to_frame()\n",
    "    tokenized_titles=[]\n",
    "    title_column[\"tokenized_title\"] = \"\"\n",
    "    for index, row in title_column.iterrows():\n",
    "        # tokenize\n",
    "        tokenized_title = word_tokenize(row.Titel)\n",
    "        \n",
    "        # remove stopwords & numbers/punction\n",
    "        tokenized_title = [word for word in tokenized_title if word not in stopwords.words(\"german\")]\n",
    "        \n",
    "        # add to row\n",
    "        row.tokenized_title = tokenized_title\n",
    "        \n",
    "    return title_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671d60f",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e6040830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_interest_over_time(keyword_list):\n",
    "    # connect to google\n",
    "    pytrends = TrendReq(hl='de', tz='60') \n",
    "\n",
    "    # keywords\n",
    "    keywords = keyword_list\n",
    "\n",
    "    # build payload\n",
    "    startDate = \"2021-11-07\"\n",
    "    dateTime=datetime.datetime.now()\n",
    "    currentDate = dateTime.strftime(\"%Y-%m-%d\")\n",
    "    timeframe = startDate +\" \"+ str(currentDate)\n",
    "    dataframes = []\n",
    "    for keyword in keywords:\n",
    "        keyword_list = []\n",
    "        keyword_list.append(keyword)\n",
    "        pytrends.build_payload(keyword_list, cat=0, timeframe= str(timeframe) ) \n",
    "        \n",
    "        # get data with interest over time\n",
    "        data = pytrends.interest_over_time() \n",
    "        dataframes.append(data)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # concat all google trends results\n",
    "    dfs = pd.concat(dataframes, axis=1)\n",
    "    # remove deprecated column\n",
    "    dfs=dfs.loc[:,~dfs.columns.str.startswith('isPartial')]\n",
    "\n",
    "    # get df to right format\n",
    "    google_df = dfs.unstack().reset_index() \n",
    "    google_df = google_df.rename(columns={\"level_0\" : \"KeyWord\", 0 : \"Occurence_in_Google\"})\n",
    "    \n",
    "    #fill all NaN with 0\n",
    "    google_df[\"Occurence_in_Google\"] = google_df[\"Occurence_in_Google\"].fillna(0)\n",
    "    google_df[\"Occurence_in_Google\"] = google_df[\"Occurence_in_Google\"].astype(int)\n",
    "    \n",
    "    google_df[\"Occurence_in_Google_normalized\"] = google_df[\"Occurence_in_Google\"].div(100)\n",
    "    return google_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6034d0",
   "metadata": {},
   "source": [
    "### Titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "236ed23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurence_of_all_titles(data_frame, columnName):\n",
    "    # Group titles by columnName\n",
    "    all_titles = data_frame.groupby(columnName).size()\n",
    "    \n",
    "    #sort titles\n",
    "    all_titles = all_titles.sort_values(ascending = False)\n",
    "    \n",
    "    return all_titles\n",
    "\n",
    "def get_occurence_of_all_capital_titles(data_frame, columnName):\n",
    "    all_titles=data_frame.groupby(columnName).size()\n",
    "\n",
    "    capital_titles=[]\n",
    "    counter=0\n",
    "    for title in all_titles.items():\n",
    "        title_s=str(title)\n",
    "        title_s=title_s.strip()\n",
    "        if title_s.istitle():\n",
    "            capital_titles.append(title)        \n",
    "    Titles = pd.DataFrame.from_records(\n",
    "    capital_titles, columns=['Title','Occurence'])\n",
    "    return Titles.sort_values(by=['Occurence'],ascending=False)\n",
    "\n",
    "def get_titles_with_minimum_occurence_N(data_frame, N):\n",
    "    all_Titles = get_occurence_of_all_capital_titles(data_frame, \"tokenized_titles\")\n",
    "    above_N = []\n",
    "    for index,row in all_Titles.iterrows():\n",
    "        if int(row.Occurence) >= N:\n",
    "            above_N.append(row)\n",
    "            \n",
    "    above_N = pd.DataFrame(above_N, columns=['Title', 'Occurence'])\n",
    "\n",
    "    return data_frame[data_frame[\"tokenized_titles\"].isin(above_N.Title)]\n",
    "\n",
    "def get_titles_with_minimum_occurence_N(data_frame, N):\n",
    "    all_Titles = get_occurence_of_all_capital_titles(data_frame, \"tokenized_titles\")\n",
    "    above_N = []\n",
    "    for index,row in all_Titles.iterrows():\n",
    "        if int(row.Occurence) >= N:\n",
    "            above_N.append(row)\n",
    "            \n",
    "    above_N = pd.DataFrame(above_N, columns=['Title', 'Occurence'])\n",
    "\n",
    "    return data_frame[data_frame[\"tokenized_titles\"].isin(above_N.Title)]        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c815d2",
   "metadata": {},
   "source": [
    "# Build big Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfe577f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_articles[\"tokenized_titles\"] = explode_titles(All_articles[\"Titel\"]).tokenized_title\n",
    "All_articles = All_articles.explode(\"tokenized_titles\")\n",
    "uninteresting_titles= [\"Der\", \"Die\", \"Das\",\"Was\",\"Warum\",\"Er\",\"Sie\", \"Es\", \"Ich\", \"Du\", \"Mit\",\"Wie\",\"Ein\",\"So\",\"Wir\",\n",
    "                       \":\",\"»\",\"«\", \",\" ,\"\\'\\'\",\"``\", \"_\",\"-\" \".\",\"?\",\"–\", \"-\",\".\",\"!\"]\n",
    "\n",
    "All_articles=All_articles[~All_articles.tokenized_titles.isin(uninteresting_titles)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64812edc",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e4ac2b",
   "metadata": {},
   "source": [
    "### Ammount of articles with occurence above n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3bec31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:10 = 1811\n",
      "n:25 = 584\n",
      "n:50 = 239\n",
      "n:75 = 125\n",
      "n:100 = 72\n",
      "n:125 = 48\n",
      "n:150 = 35\n",
      "n:200 = 21\n"
     ]
    }
   ],
   "source": [
    "occurence = [10,25,50,75,100,125,150,200]\n",
    "for n in occurence:\n",
    "    x = get_titles_with_minimum_occurence_N(All_articles, n)\n",
    "    y = get_occurence_of_all_capital_titles(x,\"tokenized_titles\")\n",
    "    print(\"n:\"+str(n) +\" = \"+str(len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fd45b",
   "metadata": {},
   "source": [
    "# Build Occurence DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "746fa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Occurence_df(dataframe, n_occurences):\n",
    "    article_over_occurence = get_titles_with_minimum_occurence_N(dataframe[[\"Date_Info\", \"tokenized_titles\"]], n_occurences)\n",
    "\n",
    "    # prep keyword list \"Titles\"\n",
    "    keyword_list = list(article_over_occurence[\"tokenized_titles\"].drop_duplicates())\n",
    "\n",
    "    google_data = get_google_interest_over_time(keyword_list)\n",
    "\n",
    "    #rename columns\n",
    "    article_over_occurence = article_over_occurence.rename(columns={\"Date_Info\" : \"date\", \"tokenized_titles\" : \"Occurence_in_news\"})\n",
    "    #convert to datetime\n",
    "    article_over_occurence['date'] = pd.to_datetime(article_over_occurence.date) \n",
    "    #convert datetime format to googles datetime format\n",
    "    article_over_occurence['date'] = article_over_occurence['date'].dt.strftime('%Y-%m-%d')\n",
    "    #reshape our data frame to look like google data frame\n",
    "    occurence_df=article_over_occurence.pivot_table(index='date', columns='Occurence_in_news', aggfunc='size') \\\n",
    "                .rename_axis(None, axis=1)\n",
    "    #fill all NaN with 0\n",
    "    occurence_df = occurence_df.fillna(0)\n",
    "    occurence_df = occurence_df.astype(int)\n",
    "\n",
    "    # bring news df to right format\n",
    "    news_df = occurence_df.unstack().reset_index()\n",
    "    news_df = news_df.rename(columns={\"level_0\" : \"KeyWord\", 0 : \"Occurence_in_News\"})\n",
    "    news_df[\"date\"]=pd.to_datetime(news_df[\"date\"], format='%Y-%m-%d')\n",
    "    \n",
    "    # normalize Occurence_in_News\n",
    "    \n",
    "    # merge google and news\n",
    "    full_df = pd.merge(news_df, google_data, on=['KeyWord',\"date\"], how='outer')\n",
    "    #fill all NaN with 0\n",
    "    full_df[\"Occurence_in_Google\"] = full_df[\"Occurence_in_Google\"].fillna(0)\n",
    "    full_df[\"Occurence_in_Google\"] = full_df[\"Occurence_in_Google\"].astype(int)\n",
    "    data_frame_list=[]\n",
    "    for keyword in keyword_list:\n",
    "        keyworded_dataFrame = full_df.loc[full_df[\"KeyWord\"] == keyword]\n",
    "\n",
    "        df_chunk = keyworded_dataFrame\n",
    "        df_chunk[\"Occurence_in_News_Normalized\"]=(keyworded_dataFrame[\"Occurence_in_News\"]-keyworded_dataFrame[\"Occurence_in_News\"].min())/(keyworded_dataFrame[\"Occurence_in_News\"].max()-keyworded_dataFrame[\"Occurence_in_News\"].min())\n",
    "    \n",
    "        data_frame_list.append(df_chunk)\n",
    "    merged = pd.concat(data_frame_list)\n",
    "    return merged\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_Occurence_df(All_articles,50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c0878fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KeyWord</th>\n",
       "      <th>date</th>\n",
       "      <th>Occurence_in_News</th>\n",
       "      <th>Occurence_in_Google</th>\n",
       "      <th>Occurence_in_News_Normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Mann</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Mann</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Mann</td>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Mann</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Mann</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>Neue</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>Neue</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>Neue</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>Neue</td>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Neue</td>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1659 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     KeyWord       date  Occurence_in_News  Occurence_in_Google  \\\n",
       "790     Mann 2021-11-07                  1                 0.94   \n",
       "791     Mann 2021-11-08                  5                 0.88   \n",
       "792     Mann 2021-11-09                  2                 0.83   \n",
       "793     Mann 2021-11-10                  0                 0.81   \n",
       "794     Mann 2021-11-11                  1                 0.80   \n",
       "...      ...        ...                ...                  ...   \n",
       "1259    Neue 2022-01-20                  3                 0.29   \n",
       "1260    Neue 2022-01-21                  8                 0.25   \n",
       "1261    Neue 2022-01-22                  1                  NaN   \n",
       "1262    Neue 2022-01-23                  5                  NaN   \n",
       "1263    Neue 2022-01-24                  3                  NaN   \n",
       "\n",
       "      Occurence_in_News_Normalized  \n",
       "790                       0.047619  \n",
       "791                       0.238095  \n",
       "792                       0.095238  \n",
       "793                       0.000000  \n",
       "794                       0.047619  \n",
       "...                            ...  \n",
       "1259                      0.333333  \n",
       "1260                      0.888889  \n",
       "1261                      0.111111  \n",
       "1262                      0.555556  \n",
       "1263                      0.333333  \n",
       "\n",
       "[1659 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c64785c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KeyWord</th>\n",
       "      <th>date</th>\n",
       "      <th>Occurence_in_News</th>\n",
       "      <th>Occurence_in_Google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auto</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto</td>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>Zwei</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>Zwei</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>Zwei</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>Zwei</td>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>Zwei</td>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1659 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     KeyWord       date  Occurence_in_News  Occurence_in_Google\n",
       "0       Auto 2021-11-07                  0                 0.81\n",
       "1       Auto 2021-11-08                  0                 0.96\n",
       "2       Auto 2021-11-09                  1                 0.95\n",
       "3       Auto 2021-11-10                  0                 0.94\n",
       "4       Auto 2021-11-11                  0                 0.92\n",
       "...      ...        ...                ...                  ...\n",
       "1654    Zwei 2022-01-20                  7                 0.86\n",
       "1655    Zwei 2022-01-21                  7                 0.88\n",
       "1656    Zwei 2022-01-22                  4                  NaN\n",
       "1657    Zwei 2022-01-23                  6                  NaN\n",
       "1658    Zwei 2022-01-24                  5                  NaN\n",
       "\n",
       "[1659 rows x 4 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9733a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEWSPAGE\n",
    "# get all titles that occure above N\n",
    "article_over_occurence = get_titles_with_minimum_occurence_N(All_articles[[\"Date_Info\", \"tokenized_titles\"]], 50)\n",
    "\n",
    "# prep keyword list \"Titles\"\n",
    "keyword_list = list(article_over_occurence[\"tokenized_titles\"].drop_duplicates())\n",
    "\n",
    "#rename columns\n",
    "article_over_occurence = article_over_occurence.rename(columns={\"Date_Info\" : \"date\", \"tokenized_titles\" : \"Occurence_in_news\"})\n",
    "#convert to datetime\n",
    "article_over_occurence['date'] = pd.to_datetime(article_over_occurence.date) \n",
    "#convert datetime format to googles datetime format\n",
    "article_over_occurence['date'] = article_over_occurence['date'].dt.strftime('%Y-%m-%d')\n",
    "#reshape our data frame to look like google data frame\n",
    "occurence_df=article_over_occurence.pivot_table(index='date', columns='Occurence_in_news', aggfunc='size') \\\n",
    "            .rename_axis(None, axis=1)\n",
    "#fill all NaN with 0\n",
    "occurence_df = occurence_df.fillna(0)\n",
    "occurence_df = occurence_df.astype(int)\n",
    "\n",
    "# GOOGLE \n",
    "# google trends laden\n",
    "data = google_interest_over_time(keyword_list)\n",
    "# concat all google trends results\n",
    "dfs = pd.concat(data, axis=1)\n",
    "# remove deprecated column\n",
    "dfs=dfs.loc[:,~dfs.columns.str.startswith('isPartial')]\n",
    "\n",
    "\n",
    "# get current datetime for later filenames\n",
    "date_time = datetime.datetime.today().strftime(\"%d_%m_%Y\")\n",
    "# list where all plots land\n",
    "all_plots=[]\n",
    "# list where \n",
    "#iterate over keyword list\n",
    "for keyword in keyword_list:\n",
    "    # get series for news\n",
    "    news_data = occurence_df[keyword]\n",
    "    # get series for google\n",
    "    google_data = dfs[keyword]\n",
    "    \n",
    "    # rename the Series\n",
    "    news_data= news_data.rename(\"News_Data\")\n",
    "    google_data = google_data.rename(\"Google_Data\")\n",
    "    \n",
    "    # cast to dataframe \n",
    "    news_data = news_data.to_frame()\n",
    "    google_data = google_data.to_frame()\n",
    "    # reset index\n",
    "    news_data = news_data.reset_index()\n",
    "    \n",
    "    news_data['date'] = pd.to_datetime(news_data.date) \n",
    "    merged_data = pd.merge(news_data,google_data, how=\"outer\", on=\"date\")\n",
    "    merged_data.to_csv(\"/Users/jan/Documents/Python_Projects/Bachelorthesis/Analysis/News_vs_Google/news_vs_google\"+date_time+\"_\"+keyword +\".csv\",index=False)\n",
    "    all_plots.append(createFigure(merged_data,keyword))\n",
    "\n",
    "\n",
    "# save all figures in one pdf\n",
    "with PdfPages(\"/Users/jan/Documents/Python_Projects/Bachelorthesis/Analysis/News_vs_Google/news_vs_google\"+date_time +\".pdf\") as pdf:\n",
    "    for plot in all_plots:\n",
    "        pdf.savefig(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cb285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFigure(data_frame, fileName):\n",
    "    plot = data_frame.plot.line(x=\"date\",y=[1,2],figsize=(20,10), title=\"Occurence of \"+fileName)\n",
    "    Correlation = data_frame[\"News_Data\"].corr(data_frame[\"Google_Data\"])\n",
    "    plot.annotate(\"Correlation: \" + str(Correlation) , xy=(0.05, 0.95), xycoords='axes fraction')    \n",
    "    return plot.get_figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd6958",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e7fe5",
   "metadata": {},
   "source": [
    "### Plot occurence of top 50 titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aae462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all titles\n",
    "all_titles = get_occurence_of_all_titles(All_articles,\"tokenized_titles\")\n",
    "\n",
    "# get top 50\n",
    "top50_titles = all_titles[:50]\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "top50_titles.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653fd5e",
   "metadata": {},
   "source": [
    "### Plot occurence of top 50 titles starting with capital letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all titles\n",
    "all_titles = get_occurence_of_all_capital_titles(All_articles,\"tokenized_titles\")\n",
    "\n",
    "#get top 50\n",
    "top50_titles = all_titles[:50]\n",
    "\n",
    "#plot\n",
    "top50_titles.plot.bar(x=\"Title\",y=\"Occurence\",figsize=(20, 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
