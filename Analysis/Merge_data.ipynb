{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Pandas is an open source data analysis and manipulation tool\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# os gives access to the operating system\n",
    "import os\n",
    "# The datetime module supplies classes for manipulating dates and times.\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "# This module provides various time-related functions.\n",
    "import time\n",
    "\n",
    "# Natural language toolkit\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# library to create visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "\n",
    "# open source library for automating downloading of reports from Google Trends\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "# library to get html of website (wikipedia)\n",
    "import requests\n",
    "# json to use wikipedia return\n",
    "import json\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\AppData\\Local\\Temp\\ipykernel_21796\\2850329852.py:7: DtypeWarning: Columns (1,5,6,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  News_DataFrame = pd.read_csv(path+filename_news, index_col=None,header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 584887 entries, 0 to 584886\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Titel                  584887 non-null  object \n",
      " 1   Overline               485780 non-null  object \n",
      " 2   Date_Info              584887 non-null  object \n",
      " 3   Kategorie              576257 non-null  object \n",
      " 4   URL                    584887 non-null  object \n",
      " 5   detailed_informations  203986 non-null  object \n",
      " 6   bild_plus              125880 non-null  object \n",
      " 7   Zugriff_Datum          493280 non-null  float64\n",
      " 8   News_page              584887 non-null  object \n",
      " 9   Breadcrumb             276660 non-null  object \n",
      " 10  author                 55600 non-null   object \n",
      " 11  Titel_and_Overline     584887 non-null  object \n",
      " 12  Tokens                 584887 non-null  object \n",
      "dtypes: float64(1), object(12)\n",
      "memory usage: 58.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load exploded dataframe\n",
    "path = \"C:/Users/Jan/Documents/Python_Projects/Bachelorthesis/Bachelorthesis/Analysis/DataFrames/\"\n",
    "filename_news = \"All_news_articles_exploded.csv\"\n",
    "filename_Google = \"Google_DataFrame.csv\"\n",
    "filename_wiki = \"Wikipedia_DataFrame.csv\"\n",
    "\n",
    "News_DataFrame = pd.read_csv(path+filename_news, index_col=None,header=0)\n",
    "Google_DataFrame = pd.read_csv(path+filename_Google, index_col=None,header=0)\n",
    "Wiki_DataFrame = pd.read_csv(path+filename_wiki, index_col=None,header=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Only use keywords that occured above n = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "             KeyWord        date  Occurence_in_Wikipedia  \\\n0                 2G  2022-01-10                      38   \n1                 2G  2022-01-11                      39   \n2                 2G  2022-01-12                      49   \n3                 2G  2022-01-13                      49   \n4                 2G  2022-01-14                      54   \n...              ...         ...                     ...   \n219866  Überraschung  2022-07-02                      21   \n219867  Überraschung  2022-07-03                      17   \n219868  Überraschung  2022-07-04                      26   \n219869  Überraschung  2022-07-05                      41   \n219870  Überraschung  2022-07-06                      32   \n\n        normalized_Occurence_in_Wikipedia  Occurence_in_Google  \\\n0                                0.092910                   97   \n1                                0.095355                  100   \n2                                0.119804                   86   \n3                                0.119804                   78   \n4                                0.132029                   83   \n...                                   ...                  ...   \n219866                           0.265823                   14   \n219867                           0.215190                   14   \n219868                           0.329114                   10   \n219869                           0.518987                   12   \n219870                           0.405063                    0   \n\n        normalized_Occurence_in_Google  \n0                                 0.97  \n1                                 1.00  \n2                                 0.86  \n3                                 0.78  \n4                                 0.83  \n...                                ...  \n219866                            0.14  \n219867                            0.14  \n219868                            0.10  \n219869                            0.12  \n219870                            0.00  \n\n[219871 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>KeyWord</th>\n      <th>date</th>\n      <th>Occurence_in_Wikipedia</th>\n      <th>normalized_Occurence_in_Wikipedia</th>\n      <th>Occurence_in_Google</th>\n      <th>normalized_Occurence_in_Google</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2G</td>\n      <td>2022-01-10</td>\n      <td>38</td>\n      <td>0.092910</td>\n      <td>97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2G</td>\n      <td>2022-01-11</td>\n      <td>39</td>\n      <td>0.095355</td>\n      <td>100</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2G</td>\n      <td>2022-01-12</td>\n      <td>49</td>\n      <td>0.119804</td>\n      <td>86</td>\n      <td>0.86</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2G</td>\n      <td>2022-01-13</td>\n      <td>49</td>\n      <td>0.119804</td>\n      <td>78</td>\n      <td>0.78</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2G</td>\n      <td>2022-01-14</td>\n      <td>54</td>\n      <td>0.132029</td>\n      <td>83</td>\n      <td>0.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>219866</th>\n      <td>Überraschung</td>\n      <td>2022-07-02</td>\n      <td>21</td>\n      <td>0.265823</td>\n      <td>14</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>219867</th>\n      <td>Überraschung</td>\n      <td>2022-07-03</td>\n      <td>17</td>\n      <td>0.215190</td>\n      <td>14</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>219868</th>\n      <td>Überraschung</td>\n      <td>2022-07-04</td>\n      <td>26</td>\n      <td>0.329114</td>\n      <td>10</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>219869</th>\n      <td>Überraschung</td>\n      <td>2022-07-05</td>\n      <td>41</td>\n      <td>0.518987</td>\n      <td>12</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>219870</th>\n      <td>Überraschung</td>\n      <td>2022-07-06</td>\n      <td>32</td>\n      <td>0.405063</td>\n      <td>0</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>219871 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "df = build_Occurence_df(News_DataFrame,50, Wiki_DataFrame, Google_DataFrame)\n",
    "saveCSV(df,\"Occurence_DataFrame\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def build_Occurence_df(news_dataFrame, n_occurences, wikipedia_DataFrame, google_DataFrame):\n",
    "    article_over_occurence = get_titles_with_minimum_occurence_N(news_dataFrame[[\"Date_Info\", \"Tokens\",\"Kategorie\"]], n_occurences)\n",
    "\n",
    "    # prep keyword list \"Titles\"\n",
    "    keyword_list = list(article_over_occurence[\"Tokens\"].drop_duplicates())\n",
    "    # get google data\n",
    "    google_data = google_DataFrame.copy()\n",
    "    # get wikipedia data\n",
    "    wikipedia_data = wikipedia_DataFrame.copy()\n",
    "\n",
    "    #rename columns\n",
    "    article_over_occurence = article_over_occurence.rename(columns={\"Date_Info\" : \"date\", \"Tokens\" : \"Occurence_in_news\"})\n",
    "    #convert to datetime\n",
    "    article_over_occurence['date'] = pd.to_datetime(article_over_occurence.date)\n",
    "    google_data['date'] = pd.to_datetime(google_data.date)\n",
    "    wikipedia_data['date'] = pd.to_datetime(wikipedia_data.date)\n",
    "    #convert datetime format to googles datetime format\n",
    "    article_over_occurence['date'] = article_over_occurence['date'].dt.strftime('%Y-%m-%d')\n",
    "    #reshape our data frame to look like google data frame\n",
    "    occurence_df=article_over_occurence.pivot_table(index='date', columns='Occurence_in_news', aggfunc='size').rename_axis(None, axis=1)\n",
    "    #fill all NaN with 0\n",
    "    occurence_df = occurence_df.fillna(0)\n",
    "    occurence_df = occurence_df.astype(int)\n",
    "\n",
    "    # bring news df to right format\n",
    "    news_df = occurence_df.unstack().reset_index()\n",
    "    news_df = news_df.rename(columns={\"level_0\" : \"KeyWord\", 0 : \"Occurence_in_News\"})\n",
    "    news_df[\"date\"]=pd.to_datetime(news_df[\"date\"], format='%Y-%m-%d')\n",
    "    news_df = normalize_column_by_keyword(news_df,keyword_list,\"Occurence_in_News\")\n",
    "\n",
    "    # merge google and news\n",
    "    #full_df = pd.merge(news_df, google_data, on=['KeyWord',\"date\"], how='outer')\n",
    "\n",
    "    full_df = pd.merge(pd.merge(news_df,google_data,on=['KeyWord',\"date\"]),wikipedia_data,on=['KeyWord',\"date\"])\n",
    "\n",
    "\n",
    "    #fill all NaN with 0\n",
    "    full_df[\"Occurence_in_Google\"] = full_df[\"Occurence_in_Google\"].fillna(0)\n",
    "    full_df[\"Occurence_in_Google\"] = full_df[\"Occurence_in_Google\"].astype(int)\n",
    "    return full_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def get_occurence_of_all_titles(data_frame, columnName):\n",
    "    # Group titles by columnName\n",
    "    all_titles = data_frame.groupby(columnName).size()\n",
    "\n",
    "    #sort titles\n",
    "    all_titles = all_titles.sort_values(ascending = False)\n",
    "\n",
    "    return all_titles\n",
    "\n",
    "\n",
    "def get_occurence_of_all_capital_titles(data_frame, columnName):\n",
    "    all_titles=data_frame.groupby(columnName).size()\n",
    "\n",
    "    capital_titles=[]\n",
    "    counter=0\n",
    "    for title in all_titles.items():\n",
    "        title_s=str(title)\n",
    "        title_s=title_s.strip()\n",
    "        if title_s.istitle():\n",
    "            capital_titles.append(title)\n",
    "    Titles = pd.DataFrame.from_records(\n",
    "    capital_titles, columns=['Title','Occurence'])\n",
    "    return Titles.sort_values(by=['Occurence'],ascending=False)\n",
    "\n",
    "\n",
    "def get_titles_with_minimum_occurence_N(data_frame, N):\n",
    "    all_Titles = get_occurence_of_all_capital_titles(data_frame, \"Tokens\")\n",
    "    above_N = []\n",
    "    for index,row in all_Titles.iterrows():\n",
    "        if int(row.Occurence) >= N:\n",
    "            above_N.append(row)\n",
    "\n",
    "    above_N = pd.DataFrame(above_N, columns=['Title', 'Occurence'])\n",
    "\n",
    "    return data_frame[data_frame[\"Tokens\"].isin(above_N.Title)]\n",
    "\n",
    "\n",
    "def get_titles_with_minimum_occurence_N(data_frame, N):\n",
    "    all_Titles = get_occurence_of_all_capital_titles(data_frame, \"Tokens\")\n",
    "    above_N = []\n",
    "    for index,row in all_Titles.iterrows():\n",
    "        if int(row.Occurence) >= N:\n",
    "            above_N.append(row)\n",
    "\n",
    "    above_N = pd.DataFrame(above_N, columns=['Title', 'Occurence'])\n",
    "\n",
    "    return data_frame[data_frame[\"Tokens\"].isin(above_N.Title)]\n",
    "\n",
    "\n",
    "def normalize_column_by_keyword(dataframe, keyword_list, column):\n",
    "    dataframe_list = []\n",
    "    new_column_name = \"normalized_\" + column\n",
    "    for keyword in keyword_list:\n",
    "        working_df = dataframe[dataframe['KeyWord'] == keyword]\n",
    "        max_occurence = working_df[column].max()\n",
    "        #print(max_occurence)\n",
    "        df_copy = working_df.copy()\n",
    "        df_copy[new_column_name] = working_df[column] /working_df[column].abs().max()\n",
    "        dataframe_list.append(df_copy)\n",
    "    return pd.concat(dataframe_list)\n",
    "\n",
    "\n",
    "def saveCSV(dataframe, filename):\n",
    "    dataframe.to_csv(\"C:/Users/Jan/Documents/Python_Projects/Bachelorthesis/Bachelorthesis/Analysis/DataFrames/\"+ filename +\".csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}